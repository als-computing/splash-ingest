{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with Mapping\n",
    "This notebook lets us play with the mapping that we can create guide the MappedHD5Ingestor class into producing a document stream (ingesting) from an hdf5 file.\n",
    "\n",
    "1. Build a projection\n",
    "A [projection](https://blueskyproject.io/event-model/data-model.html#projections) maps from metadata and fields in a docstream to a datastructure keyed on keys with a known ontology. Ontologies could be a structure like fields needed to recreate a NeXus file, or fields needed to display data in an application, like Splash.\n",
    "\n",
    "2. Import projections file\n",
    "For now, we have a projection stored in [projections.py](./projections.py). We're using python instead of json because we could add comments. But as long as you use double quotes instead of single quotes for strings and keys, the format is almost the same. This projection will be added to the start doc when we ingest the file.\n",
    "\n",
    "3. Build a file\n",
    "First, let's create a sample hdf5 file. We can modify the fields here and watch them update down below when we generate the docstream.\n",
    "\n",
    "4. Build a mapping\n",
    "Let's work on the mapping. You create a file...could be python or json, and provide it to the `ingestor`. The exact mechnanism for doing that has not quite been designed, yet. \n",
    "\n",
    "For now, we have a mapping stored in [mapping.py](./mapping.py). We're using python instead of json because we could add comments. But as long as you use double quotes instead of single quotes for strings and keys, the format is almost the same.\n",
    "\n",
    "5. Import the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from importlib import reload\n",
    "import json\n",
    "import os\n",
    "import pytz\n",
    "import sys\n",
    "sys.path.append(\"../..\") \n",
    "import tempfile\n",
    "from IPython.utils.tempdir import TemporaryWorkingDirectory\n",
    "from IPython.display import FileLink\n",
    "import h5py\n",
    "import numpy as np\n",
    "from docstream import MappedHD5Ingestor, MappingNotFoundError\n",
    "from docstream.model import Mapping\n",
    "\n",
    "def build_file():\n",
    "    temp_dir = TemporaryWorkingDirectory()\n",
    "    local = pytz.timezone(\"America/Los_Angeles\")\n",
    "    num_frames = 3\n",
    "    date_data_type = h5py.string_dtype(encoding='ascii')\n",
    "    image_date = np.empty((num_frames), dtype=object)\n",
    "    scan_date = np.empty((num_frames), dtype=object)\n",
    "    data = np.empty((num_frames, 16, 9))\n",
    "    data_dark = np.empty((1, 16, 9))\n",
    "    data_white = np.empty((1, 16, 9))\n",
    "\n",
    "    # three data frames\n",
    "    for x in range(0, num_frames):\n",
    "        image_date[x] = (str(local.localize(datetime.datetime.now(), is_dst=None)))\n",
    "        scan_date[x] = (str(local.localize(datetime.datetime.now(), is_dst=None)))\n",
    "        data[x, :, :] = np.random.random_sample((16, 9))\n",
    "    # one dark, one white\n",
    "    data_dark[0, :, :] = np.random.random_sample((16, 9))\n",
    "    data_white[0, :, :] = np.random.random_sample((16, 9))\n",
    "\n",
    "\n",
    "    image_date[x] = (str(local.localize(datetime.datetime.now(), is_dst=None)))\n",
    "    file = h5py.File(os.path.join(temp_dir.name, 'test.hdf5'), 'w')\n",
    "    file.create_dataset('/measurement/sample/name', data='nifty sample')\n",
    "    file.create_dataset('/measurement/instrument/name', data='my station')\n",
    "    file.create_dataset('/measurement/instrument/source/beamline', data='my beam')\n",
    "    file.create_dataset('/process/acquisition/image_date', data=image_date, dtype=date_data_type)\n",
    "    file.create_dataset('/process/acquisition/scan_date', data=scan_date, dtype=date_data_type)\n",
    "    file.create_dataset('/exchange/data', data=data)\n",
    "    file.create_dataset('/exchange/dark', data=data_dark)\n",
    "    file.create_dataset('/process/acquisition/sample_position_x', data=[1.0, 2.0])\n",
    "    file.close()\n",
    "    # reopen for reading\n",
    "    file = h5py.File(os.path.join(temp_dir.name, 'test.hdf5'), 'r')\n",
    "    yield file\n",
    "    file.close()\n",
    "\n",
    "def build_projections():\n",
    "    projections_dict = {}\n",
    "    # with open('mapping.json') as json_file:\n",
    "    #    mapping_dict = json.load(json_file)\n",
    "    import projections\n",
    "\n",
    "    reload(projections)\n",
    "    return projections.projections\n",
    "\n",
    "def build_mapping():\n",
    "    mapping_dict = {}\n",
    "    # with open('mapping.json') as json_file:\n",
    "    #    mapping_dict = json.load(json_file)\n",
    "    import mapping\n",
    "    reload(mapping)\n",
    "    mapping_dict = mapping.mapping_dict\n",
    "    # construct a mapping object from dict to validate that we typed it correctly\n",
    "    return Mapping(**mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest!\n",
    "Now we construct an instance of the MappedHD5Ingestor and ask it to generate us a docstream that reads the mapping and provides fields from the file\n",
    "\n",
    "The root directory 'test_root' variable that can help us find the file based on a configurable root dir. It will be written directly into the resource document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start: {\n \"uid\": \"915efd31-d44e-49e2-96cc-f4408b19c619\",\n \"time\": 1601481587.0551686,\n \"measurement:sample:name\": \"nifty sample\",\n \"measurement:instrument:name\": \"my station\",\n \"measurement:instrument:source:beamline\": \"my beam\",\n \"projections\": [\n  {\n   \"name\": \"app_display\",\n   \"version\": \"42.0.0\",\n   \"configuration\": {},\n   \"projection\": {\n    \"/entry/instrument/detector/data\": {\n     \"type\": \"linked\",\n     \"location\": \"event\",\n     \"stream\": \"primary\",\n     \"field\": \"entry/instrument/detector/data\"\n    }\n   }\n  }\n ]\n}\nresource\ndescriptor\ndatum\nevent\ndatum\nevent\ndatum\nevent\ndescriptor\ndatum\nevent\nstop: {\n \"uid\": \"d72d9c0d-30f3-417e-8ac7-f31b5d0589b7\",\n \"time\": 1601481587.0609992,\n \"run_start\": \"915efd31-d44e-49e2-96cc-f4408b19c619\",\n \"exit_status\": \"success\",\n \"reason\": \"\",\n \"num_events\": {\n  \"primary\": 3,\n  \"darks\": 1\n }\n}\n"
    }
   ],
   "source": [
    "detailed_output = False\n",
    "\n",
    "file_gen = build_file()\n",
    "\n",
    "file = next(build_file())\n",
    "mapping = build_mapping()\n",
    "projections = build_projections()\n",
    "\n",
    "ingestor = MappedHD5Ingestor(mapping, file, 'find_me_in_the_resource_document', projections=projections)\n",
    "\n",
    "start_doc = {}\n",
    "stop_doc = {}\n",
    "\n",
    "# fill up a dictionary to later run a projection from\n",
    "from databroker.core import BlueskyRun, SingleRunCache\n",
    "run_cache = SingleRunCache()\n",
    "try:\n",
    "    for name, doc in ingestor.generate_docstream():\n",
    "        run_cache.callback(name, doc)\n",
    "        if name == \"start\":\n",
    "            start_doc = doc\n",
    "        if detailed_output:\n",
    "            print(\"\\n\\n===============\")\n",
    "            print(\"Document:  \" + name)\n",
    "            if name == 'event':\n",
    "                print(repr(doc))\n",
    "            else:\n",
    "                print (json.dumps(doc, indent=1))\n",
    "        else:\n",
    "            if name == 'start' or name == 'stop':\n",
    "                doc_str = json.dumps(doc, indent=1)\n",
    "                print (f\"{name}: {doc_str}\")\n",
    "            else:\n",
    "                print(name)\n",
    "       \n",
    "            \n",
    "except MappingNotFoundError as e:\n",
    "    print('Indigestion! ' + repr(e))\n",
    "    \n",
    "next(file_gen) # cleanup\n",
    "run = run_cache.retrieve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ProjectionError",
     "evalue": "error projecting field: /entry/instrument/detector/data",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/projector.py\u001b[0m in \u001b[0;36mproject_xarray\u001b[0;34m(run, projection, projection_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                     \u001b[0mdata_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprojection_stream\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprojection_linked_field\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/core.py\u001b[0m in \u001b[0;36mto_dask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;31m# Implemented just so we can put in a docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/intake_xarray_core/base.py\u001b[0m in \u001b[0;36mto_dask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m\"\"\"Return xarray object where variables are dask arrays\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/intake_xarray_core/base.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;34m\"\"\"Return xarray object (which will have chunks)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/beamline/lib/python3.8/site-packages/intake/source/base.py\u001b[0m in \u001b[0;36m_load_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatashape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatashape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/intake_xarray_core/base.py\u001b[0m in \u001b[0;36m_get_schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/core.py\u001b[0m in \u001b[0;36m_open_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m         self._ds = _documents_to_xarray(\n\u001b[0m\u001b[1;32m   1451\u001b[0m             \u001b[0mstart_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_start_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/core.py\u001b[0m in \u001b[0;36m_documents_to_xarray\u001b[0;34m(start_doc, stop_doc, descriptor_docs, get_event_pages, filler, get_resource, lookup_resource_for_datum, get_datum_pages, include, exclude)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0mevent_dim_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             data_arrays[key] = xarray.DataArray(\n\u001b[0m\u001b[1;32m    709\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/beamline/lib/python3.8/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_compatible_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_coords_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/beamline/lib/python3.8/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;34m\"different number of dimensions on data \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: different number of dimensions on data and dims: 1 vs 4",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProjectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6a0d1a567779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatabroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproject_xarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/projector.py\u001b[0m in \u001b[0;36mproject_xarray\u001b[0;34m(run, projection, projection_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mProjectionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mProjectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error projecting run'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bluesky/databroker/databroker/projector.py\u001b[0m in \u001b[0;36mproject_xarray\u001b[0;34m(run, projection, projection_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0mdata_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprojection_stream\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprojection_linked_field\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mProjectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'error projecting field: {field_key}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mprojection_location\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'configuration'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProjectionError\u001b[0m: error projecting field: /entry/instrument/detector/data"
     ]
    }
   ],
   "source": [
    "\n",
    "from databroker.projector import project_xarray\n",
    "\n",
    "xarray = project_xarray(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('beamline': conda)",
   "language": "python",
   "name": "python38564bitbeamlineconda6fd59d1623ee4b259edd84f5e2c34375"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}